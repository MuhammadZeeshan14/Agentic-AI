{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Import OpenAI SDK"
      ],
      "metadata": {
        "id": "5hE5Vzz58t9U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Wg9czC0L8Qgv"
      },
      "outputs": [],
      "source": [
        "# Install the openai-agents library\n",
        "!pip install -Uq openai-agents"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import Asyncio to run asynchronus functions"
      ],
      "metadata": {
        "id": "hTptzGhr8vdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the nest_asyncio library\n",
        "import nest_asyncio\n",
        "# Apply nest_asyncio to allow asyncio to run in a nested environment (like Colab)\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "Db6lweX58Xpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Set Gemini API key as Default API reference instaed of Open API key and Setting Up Configurations"
      ],
      "metadata": {
        "id": "yiGesVaO8zya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "from agents import Agent, Runner, AsyncOpenAI, OpenAIChatCompletionsModel\n",
        "from agents.run import RunConfig\n",
        "from google.colab import userdata\n",
        "from pydantic import BaseModel\n",
        "\n",
        "from agents import (\n",
        "    Agent,\n",
        "    Runner,\n",
        "    set_default_openai_api,\n",
        "    set_default_openai_client,\n",
        "    set_tracing_disabled,\n",
        ")\n",
        "\n",
        "# Get the Gemini API key from Colab user data secrets\n",
        "gemini_api_key = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "# Disable tracing for the agents library\n",
        "set_tracing_disabled(True)\n",
        "# Set the default OpenAI API to chat completions\n",
        "set_default_openai_api(\"chat_completions\")\n",
        "\n",
        "# Create an AsyncOpenAI client with the Gemini API key and base URL\n",
        "external_client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        ")\n",
        "# Set the default OpenAI client to the external client\n",
        "set_default_openai_client(external_client)\n",
        "\n",
        "# Create an OpenAIChatCompletionsModel instance using the Gemini 2.0 Flash model\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    openai_client= external_client\n",
        ")"
      ],
      "metadata": {
        "id": "TgNT5cmj8doF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hosted Tools: WebSearch Tool, FileSearch Tool, Computer Tool"
      ],
      "metadata": {
        "id": "rVMfSsPA83y5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary components from the agents library\n",
        "from agents import Agent, FileSearchTool, Runner, WebSearchTool # hosted tools require OPEN API key so it won't work with Gemini\n",
        "\n",
        "# Create an Agent named \"Assistant\" with WebSearchTool and FileSearchTool\n",
        "agent = Agent(\n",
        "    name=\"Assistant\",\n",
        "    tools=[\n",
        "        WebSearchTool(), # Tool for web searching\n",
        "        FileSearchTool( # Tool for file searching\n",
        "            max_num_results=3, # Maximum number of results to return\n",
        "            # vector_store_ids=[\"VECTOR_STORE_ID\"], # Example of how to specify vector store IDs\n",
        "            vector_store_ids=[\"vs_6813268d82a081919782a0990f3a68f9\"], # Specific vector store ID\n",
        "        ),\n",
        "    ],\n",
        ")"
      ],
      "metadata": {
        "id": "ogkOwrLm87Rs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the agent synchronously with the input \"Show Muhammad Qasim current organization and job title\"\n",
        "result =  Runner.run_sync(agent, \"Show Muhammad Qasim current organization and job title\")\n",
        "# Print the final output from the agent's run\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "id": "givnldvG-XEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Streaming\n",
        "##1. Streaming Text code"
      ],
      "metadata": {
        "id": "jB0fZA1OCW_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import asyncio\n",
        "\n",
        "from openai.types.responses import ResponseTextDeltaEvent\n",
        "\n",
        "from agents import Agent, Runner\n",
        "\n",
        "\n",
        "# Define an asynchronous main function\n",
        "async def main():\n",
        "    # Create an Agent named \"Joker\" with instructions and the specified model\n",
        "    agent = Agent(\n",
        "        name=\"Joker\",\n",
        "        instructions=\"You are a helpful assistant.\",\n",
        "        model=model\n",
        "    )\n",
        "\n",
        "    # Run the agent with streaming enabled and the input \"Please tell me 5 jokes.\"\n",
        "    result = Runner.run_streamed(agent, input=\"Please tell me 5 jokes.\")\n",
        "    # Iterate through the streamed events\n",
        "    async for event in result.stream_events():\n",
        "        # Check if the event is a raw response event and contains text delta\n",
        "        if event.type == \"raw_response_event\" and isinstance(event.data, ResponseTextDeltaEvent):\n",
        "            # Print the text delta without a newline, flushing the output immediately\n",
        "            print(event.data.delta, end=\"\", flush=True)\n",
        "\n",
        "\n",
        "# Run the main asynchronous function\n",
        "asyncio.run(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ku_Rw3ibCbJa",
        "outputId": "2f6d45f8-6b0f-4235-f2a4-6f3ec5e8692a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alright, here are 5 jokes for you:\n",
            "\n",
            "1.  Why don't scientists trust atoms?\n",
            "    Because they make up everything!\n",
            "\n",
            "2.  What do you call a lazy kangaroo?\n",
            "    Pouch potato!\n",
            "\n",
            "3.  Why did the bicycle fall over?\n",
            "    Because it was two tired!\n",
            "\n",
            "4.  Why did the scarecrow win an award?\n",
            "    Because he was outstanding in his field!\n",
            "\n",
            "5.  What musical instrument is found in the bathroom?\n",
            "    A tuba toothpaste.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Stream item code"
      ],
      "metadata": {
        "id": "UaIFyCCuDR7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import asyncio\n",
        "import random\n",
        "\n",
        "from agents import Agent, ItemHelpers, Runner, function_tool\n",
        "\n",
        "\n",
        "# Define a function tool that returns a random integer between 1 and 10\n",
        "@function_tool\n",
        "def how_many_jokes() -> int:\n",
        "    return random.randint(1, 10)\n",
        "\n",
        "\n",
        "# Define an asynchronous main function\n",
        "async def main():\n",
        "    # Create an Agent named \"Joker\" with instructions, the defined tool, and the specified model\n",
        "    agent = Agent(\n",
        "        name=\"Joker\",\n",
        "        instructions=\"First call the `how_many_jokes` tool, then tell that many jokes.\",\n",
        "        tools=[how_many_jokes],\n",
        "        model=model\n",
        "    )\n",
        "\n",
        "    # Run the agent with streaming enabled and the input \"Hello\"\n",
        "    result = Runner.run_streamed(\n",
        "        agent,\n",
        "        input=\"Hello\",\n",
        "\n",
        "    )\n",
        "    print(\"=== Run starting ===\")\n",
        "    # Iterate through the streamed events\n",
        "    async for event in result.stream_events():\n",
        "        # Ignore raw response event deltas\n",
        "        if event.type == \"raw_response_event\":\n",
        "            continue\n",
        "        # Print a message when the agent is updated\n",
        "        elif event.type == \"agent_updated_stream_event\":\n",
        "            print(f\"Agent updated: {event.new_agent.name}\")\n",
        "            continue\n",
        "        # Handle different types of run item stream events\n",
        "        elif event.type == \"run_item_stream_event\":\n",
        "            if event.item.type == \"tool_call_item\":\n",
        "                print(\"-- Tool was called\")\n",
        "            elif event.item.type == \"tool_call_output_item\":\n",
        "                print(f\"-- Tool output: {event.item.output}\")\n",
        "            elif event.item.type == \"message_output_item\":\n",
        "                print(f\"-- Message output:\\n {ItemHelpers.text_message_output(event.item)}\")\n",
        "            else:\n",
        "                pass  # Ignore other event types\n",
        "\n",
        "\n",
        "# Run the main asynchronous function\n",
        "asyncio.run(main())\n",
        "\n",
        "print(\"=== Run complete ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldkOQ9a6DWCg",
        "outputId": "560ab110-9cac-45ad-bc46-7960428d3218"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Run starting ===\n",
            "Agent updated: Joker\n",
            "-- Tool was called\n",
            "-- Tool output: 2\n",
            "-- Message output:\n",
            " I am programmed to tell 2 jokes.\n",
            "\n",
            "Why don't scientists trust atoms?\n",
            "\n",
            "Because they make up everything!\n",
            "\n",
            " параллельно\n",
            "\n",
            "Why did the scarecrow win an award?\n",
            "\n",
            "Because he was outstanding in his field!\n",
            "\n",
            "=== Run complete ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Context\n",
        "##1. Local Context"
      ],
      "metadata": {
        "id": "EWArc-2aFkfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import asyncio\n",
        "from dataclasses import dataclass\n",
        "\n",
        "from agents import Agent, RunContextWrapper, Runner, function_tool\n",
        "\n",
        "# Define a dataclass to hold user information\n",
        "@dataclass\n",
        "class UserInfo1():\n",
        "    name: str\n",
        "    uid: int\n",
        "    age: int\n",
        "    location: str = \"Pakistan\" # Default location is Pakistan\n",
        "\n",
        "\n",
        "# Define a function tool to fetch user's age\n",
        "@function_tool\n",
        "async def fetch_user_age(wrapper: RunContextWrapper[UserInfo1]) -> str:\n",
        "    '''Returns the name and age of the user.'''\n",
        "\n",
        "    print(\"[-> Tool]\",wrapper,\"\\n\\n\")\n",
        "    return f\"User {wrapper.context.name} is {wrapper.context.age} years old\"\n",
        "\n",
        "# Define a function tool to fetch user's location\n",
        "@function_tool\n",
        "async def fetch_user_location(wrapper: RunContextWrapper[UserInfo1]) -> str:\n",
        "    '''Returns the location of the user.'''\n",
        "    return f\"User {wrapper.context.name} is from {wrapper.context.location}\"\n",
        "\n",
        "# Define an asynchronous main function\n",
        "async def main():\n",
        "    # Create an instance of UserInfo1\n",
        "    user_info = UserInfo1(name=\"Muhammad Qasim\", uid=123,age=30)\n",
        "\n",
        "    # Create an Agent with UserInfo1 context, tools, and the specified model\n",
        "    agent = Agent[UserInfo1](\n",
        "        name=\"Assistant\",\n",
        "        tools=[fetch_user_age,fetch_user_location],\n",
        "        model=model\n",
        "    )\n",
        "\n",
        "    # Run the agent with the input and user_info as context\n",
        "    result = await Runner.run(\n",
        "        starting_agent=agent,\n",
        "        input=\"What is the age of the user? current location of his/her?\",\n",
        "        context=user_info,\n",
        "    )\n",
        "\n",
        "    # Print the final output from the agent's run\n",
        "    print(result.final_output)\n",
        "    # Expected output: The user John is 47 years old.\n",
        "\n",
        "# Run the main asynchronous function if the script is executed directly\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRFgS-7SF0cq",
        "outputId": "1d8c11f4-f03b-4111-930e-1fb04e3eaf7c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-> Tool] ToolContext(context=UserInfo1(name='Muhammad Qasim', uid=123, age=30, location='Pakistan'), usage=Usage(requests=1, input_tokens=41, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=10, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=51), tool_call_id='') \n",
            "\n",
            "\n",
            "The user Muhammad Qasim is 30 years old and is from Pakistan.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Dynamic Instructions with context"
      ],
      "metadata": {
        "id": "qSz29OlmGXuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import asyncio\n",
        "import random\n",
        "from typing import Literal\n",
        "\n",
        "from agents import Agent, RunContextWrapper, Runner\n",
        "\n",
        "# Define a class for custom context with a style attribute\n",
        "class CustomContext:\n",
        "    def __init__(self, style: Literal[\"haiku\", \"pirate\", \"robot\"]):\n",
        "        self.style = style\n",
        "\n",
        "# Define a function to generate dynamic instructions based on the context style\n",
        "def custom_instructions(\n",
        "    run_context: RunContextWrapper[CustomContext], agent: Agent[CustomContext]\n",
        ") -> str:\n",
        "    context = run_context.context\n",
        "    if context.style == \"haiku\":\n",
        "        return \"Only respond in haikus.\"\n",
        "    elif context.style == \"pirate\":\n",
        "        return \"Respond as a pirate.\"\n",
        "    else:\n",
        "        return \"Respond as a robot and say 'beep boop' a lot.\"\n",
        "\n",
        "# Create an Agent with dynamic instructions and the specified model\n",
        "agent = Agent(\n",
        "    name=\"Chat agent\",\n",
        "    instructions=custom_instructions,\n",
        "    model=model\n",
        ")\n",
        "\n",
        "# Define an asynchronous main function\n",
        "async def main():\n",
        "    # Randomly choose a style for the custom context\n",
        "    choice: Literal[\"haiku\", \"pirate\", \"robot\"] = random.choice([\"haiku\", \"pirate\", \"robot\"])\n",
        "    # Create an instance of CustomContext with the chosen style\n",
        "    context = CustomContext(style=choice)\n",
        "    print(f\"Using style: {choice}\\n\")\n",
        "\n",
        "    user_message = \"Tell me a joke.\"\n",
        "    print(f\"User: {user_message}\")\n",
        "    # Run the agent with the user message and custom context\n",
        "    result = await Runner.run(agent, user_message, context=context)\n",
        "\n",
        "    # Print the final output from the agent's run\n",
        "    print(f\"Assistant: {result.final_output}\")\n",
        "\n",
        "# Run the main asynchronous function if the script is executed directly\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rU0EkIY2Geax",
        "outputId": "df19373a-fe78-4045-acd0-ff3de97a059c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using style: pirate\n",
            "\n",
            "User: Tell me a joke.\n",
            "Assistant: Aye, I've got a joke for ye, sure as the sea is blue!\n",
            "\n",
            "Why don't pirates take a shower?\n",
            "\n",
            "... Because they just wash up on shore! \n",
            "\n",
            "Har har har! Did ye find that funny, me hearty? Or should I walk the plank and find another?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Agent/LLM context"
      ],
      "metadata": {
        "id": "o04gOt9GGjvx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import asyncio\n",
        "from dataclasses import dataclass\n",
        "\n",
        "from agents import Agent, RunContextWrapper, Runner, function_tool\n",
        "\n",
        "# Define a dataclass to hold user information\n",
        "@dataclass\n",
        "class UserInfo:\n",
        "    name: str\n",
        "    uid: int\n",
        "\n",
        "# Define a function tool to greet the user with a specialized message\n",
        "@function_tool\n",
        "async def greet_user(context: RunContextWrapper[UserInfo], greeting: str) -> str:\n",
        "  \"\"\"Greets the User with their name.\n",
        "  Args:\n",
        "    greeting: A specialized greeting message for user\n",
        "  \"\"\"\n",
        "  name = context.context.name\n",
        "  return f\"Hello {name}, {greeting}\"\n",
        "\n",
        "# Define an asynchronous main function\n",
        "async def main():\n",
        "    # Create an instance of UserInfo\n",
        "    user_info = UserInfo(name=\"Muhammad Qasim\", uid=123)\n",
        "\n",
        "    # Create an Agent with UserInfo context, the greet_user tool, and the specified model\n",
        "    agent = Agent[UserInfo](\n",
        "        name=\"Assistant\",\n",
        "        tools=[greet_user],\n",
        "        model=model,\n",
        "        # Dynamic function context passed in instructions/system prompt/developer prompt\n",
        "        instructions=\"Always greet the user using <function_call>greet_user</function_call> and welcome them to Panaversity, then answer the user's prompt\"\n",
        "    )\n",
        "\n",
        "    # Run the agent with the input and user_info as context\n",
        "    result = await Runner.run(\n",
        "        starting_agent=agent,\n",
        "        input=\"who is the founder of pakistan\",\n",
        "        context=user_info,\n",
        "    )\n",
        "\n",
        "    # Print the final output from the agent's run\n",
        "    print(result.final_output)\n",
        "\n",
        "# Run the main asynchronous function\n",
        "asyncio.run(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4auSOATGoPc",
        "outputId": "9e82f0b6-7f5e-4526-8dba-4a59f2b03f27"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello Muhammad Qasim, Hello! Welcome to Panaversity!\n",
            "\n",
            "Muhammad Ali Jinnah is considered the founder of Pakistan.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}